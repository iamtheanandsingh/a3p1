{"cells":[{"cell_type":"code","execution_count":null,"metadata":{"application/vnd.databricks.v1+cell":{"cellMetadata":{},"inputWidgets":{},"nuid":"5a29dc67-bb10-44ed-bde4-e19e8014f06e","showTitle":false,"title":""}},"outputs":[],"source":["pip install spacy\n","python -m spacy download en\n","nlp = spacy.load('en_core_web_sm')"]},{"cell_type":"code","execution_count":null,"metadata":{"application/vnd.databricks.v1+cell":{"cellMetadata":{},"inputWidgets":{},"nuid":"78d7bda5-7acb-4bd4-908b-96bef3c19e3d","showTitle":false,"title":""}},"outputs":[],"source":["# create a streaming DataFrame that reads from the Kafka topic\n","df = spark.readStream.format('kafka') \\\n","    .option('kafka.bootstrap.servers', 'localhost:9092') \\\n","    .option('subscribe', 'assignment3part1_read') \\\n","    .load() \\\n","    .selectExpr('CAST(value AS STRING)')\n","\n","words = df.select(explode([entity.text for entity in nlp(df.value).ents])).alias('named_entities')\n","word_count = words.groupBy('named_entities').agg(count('*').alias('count'))\n","\n","# create a streaming DataFrame that writes the word count to another Kafka topic\n","word_count.writeStream.format('kafka') \\\n","    .option('kafka.bootstrap.servers', 'localhost:9092') \\\n","    .option('topic', 'assignment3part1_write') \\\n","    .option('checkpointLocation', '/tmp/checkpoint') \\\n","    .start() \\\n","    .awaitTermination()"]}],"metadata":{"application/vnd.databricks.v1+notebook":{"dashboards":[],"language":"python","notebookMetadata":{"pythonIndentUnit":4},"notebookName":"Assignment 3 ( Part 1 )","notebookOrigID":173284580791613,"widgets":{}},"language_info":{"name":"python"}},"nbformat":4,"nbformat_minor":0}
